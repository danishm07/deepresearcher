[
  {
    "title": "Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making",
    "summary": "Advances in artificial intelligence (AI) and machine learning (ML) have led to the development of new types of AI systems, such as natural language processing (NLP) and deep learning.",
    "datasets": [],
    "source_url": "https://arxiv.org/abs/2405.16424v1",
    "authors": [
      "Min Hun Lee",
      "Silvana Xin Yi Choo",
      "Shamala D/O Thilarajah"
    ],
    "tags": []
  },
  {
    "id": "2207.11361v1",
    "title": "Machine Learning Modeling to Evaluate the Value of Football Players",
    "summary": "The value of a football player is an important issue for managers, players, and fans alike, as it affects the competitiveness of the team and the financial viability of the club.",
    "datasets": [],
    "source_url": "https://arxiv.org/abs/2207.11361v1",
    "authors": [
      "Chenyao Li",
      "Stylianos Kampakis",
      "Philip Treleaven"
    ],
    "tags": []
  },
  {
    "id": "2406.19655v1",
    "title": "Basketball-SORT: An Association Method for Complex Multi-object Occlusion Problems in Basketball Multi-object Tracking",
    "summary": "In this paper, we propose a new multi-object tracking approach for basketball sports scenes, which is more accurate and robust than other popular approaches.",
    "datasets": [],
    "source_url": "https://arxiv.org/abs/2406.19655v1",
    "authors": [
      "Qingrui Hu",
      "Atom Scott",
      "Calvin Yeung",
      "Keisuke Fujii"
    ],
    "full_text": "Basketball-SORT: An Association Method for\nComplex Multi-object Occlusion Problems in\nBasketball Multi-object Tracking\nQingrui Hu1, Atom Scott1, Calvin Yeung1, Keisuke Fujii1,2,3*\n1Graduate School of Informatics, Nagoya University, Chikusa-ku,\nNagoya, Aichi, Japan.\n2RIKEN Center for Advanced Intelligence Project, 1-5, Yamadaoka,\nSuita, Osaka, Japan.\n3PRESTO, Japan Science and Technology Agency, Kawaguchi,\nSaitama,Japan.\n*Corresponding author(s). E-mail(s): fujii@i.nagoya-u.ac.jp;\nContributing authors: hu.qingrui@g.sp.m.is.nagoya-u.ac.jp;\natom.james.scott@gmail.com; yeung.chikwong@g.sp.m.is.nagoya-u.ac.jp;\nAbstract\nRecent deep learning-based object detection approaches have led to significant\nprogress in multi-object tracking (MOT) algorithms. The current MOT meth-\nods mainly focus on pedestrian or vehicle scenes, but basketball sports scenes\nare usually accompanied by three or more object occlusion problems with similar\nappearances and high-intensity complex motions, which we call complex multi-\nobject occlusion (CMOO). Here, we propose an online and robust MOT approach,\nnamed Basketball-SORT, which focuses on the CMOO problems in basketball\nvideos. To overcome the CMOO problem, instead of using the intersection-over-\nunion-based (IoU-based) approach, we use the trajectories of neighboring frames\nbased on the projected positions of the players. Our method designs the basket-\nball game restriction (BGR) and reacquiring Long-Lost IDs (RLLI) based on the\ncharacteristics of basketball scenes, and we also solve the occlusion problem based\non the player trajectories and appearance features. Experimental results show\nthat our method achieves a Higher Order Tracking Accuracy (HOTA) score of\n63.48% on the basketball fixed video dataset and outperforms other recent popu-\nlar approaches. Overall, our approach solved the CMOO problem more effectively\nthan recent MOT algorithms.\n1\narXiv:2406.19655v1  [cs.CV]  28 Jun 2024\nKeywords: person re-identification, sports, computer vision, video processing\n1 Introduction\nMulti-object tracking (MOT) is a fundamental computer vision task that aims to track\nmultiple objects in a video and localize them in each frame. It involves the simul-\ntaneous detection, localization, and tracking of multiple objects in a video sequence.\nIt has become increasingly important in various fields such as autonomous driving\n[1], surveillance [2, 3], and sports analysis [4], most recent tracking algorithms which\nmainly focus on crowded street scenes [2, 3], static dancing [5], driving scenarios [1]\nand sports analysis [4].\nCurrently, the most popular approach for MOT is tracking-by-detection. The pro-\ncess of the tracking-by-detection MOT method [6\u20138] usually consists of the following\nsteps: (1) Object detection: First, an object detection algorithm is used to detect\nthe target in each frame. (2) Object association: The targets detected in consecutive\nframes are associated. The association is achieved by matching the target detected\nin the current frame with the previously tracked target, such as using the Kalman\nfilter (KF), which is famous for this task. (3) Object tracking: The tracking process\nbegins once the targets have been associated between frames. This involves estimating\nthe trajectory and state of each target over time. These current mainstream methods\n[1, 9, 10] have achieved good results on several open-source datasets, which are pri-\nmarily in pedestrian and driving scenarios. However, these methods do not perform\nwell on challenging datasets, especially on some datasets with designed sports scenar-\nios [11] since The tracking problem for sports scenarios is more complex. Nowadays,\nthe demand for sports performance analysis in sports is growing, so the field of sports\nmulti-target tracking needs more attention.\nUnlike MOT for pedestrians or vehicles, team sports face more challenges due to a\nvariety of reasons, including three or more object occlusions with similar appearance\nand high-intensity complex and unpredictable motions as illustrated in Figure 1, which\nwe call Complex Multi-object Occlusion (CMOO) problems that frequently appear\nin basketball. Previous methods used appearance-motion fusion [12, 13] or simply\nmotion-based methods [10, 14] to solve the association problems, but they did not\nfocus on CMOO problems.\nIn this paper, we propose a robust online MOT algorithm specifically designed\nfor solving the CMOO problems, called Basketball-SORT, which is inspired by the\nSORT (Simple Online and Realtime Tracking) algorithm [13]. Among various team\nsport MOT datasets [11, 15\u201317], we use the basketball fixed camera dataset from the\nTeamTrack dataset [17] to validate our approach because it includes frequent CMOO\nproblems. Our experimental results show that our algorithm effectively solves the\nCMOO problems and outperforms all other tracking algorithms on the basketball fixed\ncamera dataset.\nOur paper has three main contributions as follows. (1) We propose an online and\nrobust MOT approach, named Basketball-SORT, which solves the CMOO problems,\n2\nFig. 1 An example of Complex Multi-object Occlusion (CMOO) problems with a sequence of (a)\nto (c), including three or more player occlusions with similar appearance of players\u2019 jerseys in the\nsame team and high-intensity complex and unpredictable motion. This can greatly affect detection\nand tracking accuracy and will cause a player to be lost and an ID switch.\nincluding three or more object occlusions with similar appearance of objects and high-\nintensity and unpredictable motions. (2) We have addressed the frequent occlusion\nproblems in basketball scenes by utilizing the Re-Identification (ReID) features, posi-\ntions, and velocities of players before and after occlusions. By incorporating BGR\nand RLLI, we can resolve the issue of players losing their IDs after being occluded\nfor an extended period. (3) Experimental results show that our method achieves a\nHigher Order Tracking Accuracy (HOTA) score of 63.48% on the basketball fixed\nvideo dataset and outperforms other recent popular approaches. Overall, our approach\nsolved the CMOO problem more effectively than recent MOT algorithms.\n2 Related work\n2.1 Motion-based Multi-Object Tracking\nDespite the significant advancements in object detection algorithms, many contempo-\nrary end-to-end MOT models still fall short in performance compared to traditional\nmotion model-based tracking techniques. The Kalman filter [18] serves as the corner-\nstone for the most famous family of tracking-by-detection approaches. SORT [6] used\nlinear motion mode with IoU (intersection-over-union)-associated motion trajectory.\nByteTrack [10] used the low score detection frame to predict the missing pedestrians,\nachieving good performance by balancing the detection quality and tracking confi-\ndence. Recently, OC-SORT [14] improves correlation accuracy for nonlinear motion\nscenes using an observation-centered approach. Some methods utilize the bounding\nbox distance as the cost of the association, while some recent works utilize different\nIoU computation methods, such as calculating the BIou (the buffer of two overlapping\nboxes) [19]. Another work iteratively expanding the IoU according to different scales\nof expansion (EIoU) [20] for the bounding box association between frames, which also\ndemonstrates the effectiveness of MOT in SportsMOT [11] and SoccerNet-Tracking\n[15] dataset.\n3\n2.2 Appearance-based Multi-Object Tracking\nVisual identification serves as an intuitive cue for associating targets over time. One\nof the pioneering methods to incorporate deep visual features for object association\nis DeepSORT [13]. Several approaches [8, 13] employ ReID models to extract embed-\nding features from detections, which are then used for association. In recent years,\nthe emergence of transformers [21] has sparked a new trend in utilizing appearance\nfor MOT, where object association is formulated as a query-matching task [22\u201324].\nHowever, it has been observed that appearance-based methods tend to be less effec-\ntive when the objects of interest have similar visual characteristics [5] or are subject\nto occlusion [2], which is often the case in basketball scenarios.\n2.3 Multi-Object Tracking in Sports\nMultiple Object Tracking (MOT) in sports environments presents significantly greater\nchallenges compared to other domains where MOT is applied. This can be attributed\nto the unique characteristics of sports, such as the rapid and unpredictable move-\nments of athletes, the visual similarity among players within the same team, and the\nincreased occurrence of occlusions due to the dynamic nature of the sport. Several\nresearchers have made notable contributions to address these challenges in various\nsports. For instance, in hockey, Vats et al. [25] propose a method that integrates team\nclassification and player identification techniques to enhance tracking performance.\nIn football, Maglo et al. [26] showcase improved tracking accuracy by localizing the\nfield and players. Moreover, Sang\u00fcesa et al. [27] leverage human pose information\nand actions as embedding features to boost the tracking performance of basketball\nplayers. Huang et al. [28] tackle multiple sports scenarios, including basketball, vol-\nleyball, and football, by combining OC-SORT with appearance-based post-processing.\nOur method primarily focuses on the CMOO problem in basketball. By incorporating\nCMOO\u2019s characteristics, we aim to perform robust and accurate player tracking.\n3 Methods\nOur approach adopts the tracking-by-detection paradigm, which also enables online\ntracking without using future information. Our method has the following three steps,\nas shown in Figure 2. In Section 3.1, We first use a fine-tuning yolov8 model to detect\nall the players. We then project the players\u2019 image position information onto the\n2D court plane and associate all trajectories of each frame based on the players\u2019 2D\nposition information. Second, in Section 3.2, we set the basketball game restriction\n(BGR) according to the rules of the basketball game and reacquire the tracking ID of\nthe player in the Long-Lost state (RLLI) according to the trajectory characteristics of\nthe player. Third, in Section 3.3, due to BGR and the RLLI, the ID-increasing problem\nis converted to the ID-switch problem. A player\u2019s occlusion causes the ID-switch, and\nwe use appearance features and motion features of trajectories to solve the ID-switch\nproblem.\n4\nFig. 2 The pipeline of our Basketball-SORT algorithm. The main technical contributions are BGR\nand RLLI. BGR: In a basketball game, there can only be 10-player motion trajectories. At the 100th\nframe, we calculate the 10 longest trajectories on the court and identify them as players. RLLI: For\nthe Long-Lost state player, we compare the position and appearance information of the Long-Lost\nplayer with the new detection bounding box to determine whether the player tracking ID should be\nreacquired.\n3.1 Trajectory tracking based on projected position\nAmong various team sport MOT problems [11, 15\u201317], we consider the basketball fixed\ncamera problems from the TeamTrack dataset [17] to validate our approach because\nit includes frequent CMOO problems. Since the camera is fixed, we find the image\ncoordinates of these basketball court key points in the video based on the 20 key points\nin the standard overhead view of the court as illustrated by the red dots in Figure 3,\nand then calculate the homography matrix by the following formula:\n\uf8ee\n\uf8f0\nxc\nyc\nwc\n\uf8f9\n\uf8fb= H\n\uf8ee\n\uf8f0\nxi\nyi\n1\n\uf8f9\n\uf8fb\n(1)\nwhere (xc, yc) denotes the coordinates of the basketball court coordinate system, and\n(xi, yi) denotes the coordinates of the image coordinate system, wc denotes the scale\nfactor which can unifying projection transformations into matrixes. The homogra-\nphy matrix H can be computed from the coordinates of the key points of the 20\nstandardized courts we manually input (Figure 3).\nWe use the bottom midpoint of the detection bounding box as the player\u2019s image\ncoordinate system position to convert it into a top-view projection position. As a\nresult, we can get the relative coordinates of the players in the court\u2019s plane, which\ncould be a better help in tracking the player\u2019s position in the court. The player is\nassociated with each frame using the Kalman filter based on the position and speed\nof the projected position moving on the plane. We did not utilize the IoU association\nbecause of the frequent occurrence of CMOO where players are far apart in actual\ndistance but have completely overlapping IoUs. The reason for not employing ReID\nfor association is due to the appearance similarity caused by the players\u2019 uniforms.\n5\nFig. 3 Standard basketball court projection, We use the red dots in the figure above to convert the\nimage coordinate system coordinates to the player\u2019s position in the basketball court coordinate system\n3.2 Basketball Game Restriction and Reacquiring Long-Lost\nIDs\nIn a basketball game, there is often severe occlusion of players due to offense and\ndefense, which often leads to the lost player being assigned a new tracking ID after\nreappearing. In addition, due to the detector\u2019s limited performance and the confusion\nbetween referees and players, some referees and the audience may be detected as\nplayers and have some redundant trajectories. To solve these problems, we added the\nbasketball game restriction (BGR): because basketball games have 10 players, there\nwill only be 10 tracking IDs in a game, solving the problem of the IDs increasing. We\ncalculate the length of all trajectories at the designed frame and select the top ten\ntrajectories with the most extended lengths in the court to be recognized as players. In\nthis study, this designated frame is set at the 100th frame because referee and audience\ntrajectories are shorter, and all 10 player trajectories are available at the 100th frame.\nThese ten trajectories will be fixed, and no new trajectories will be generated.\nWhen 10 players\u2019 trajectories are determined, if a trajectory is occluded for less\nthan B frames, we define this trajectory as a Lost state. If a trajectory is lost for more\nthan B frames, we define this trajectory as a Long-Lost state. Because players usually\nplay 1-on-1, the resulting trajectory states are often defined as Lost or Long-Lost\nstates. For the Lost state player, we still use the KF to predict each frame\u2019s real-time\nposition and detection box matching. For the Long-Lost state players, we need to\nreacquire their tracking ID (RLLI). We record the player\u2019s court position, and ReID\nfeatures before the player loses. When a new detection reappears on the court, we\nreassign the player\u2019s ID by comparing the appearance similarity and distance before\ndisappearing. The appearance similarity is a vital clue for object association between\nframes, which can filter out some impossible associations. It can be calculated by the\ncosine similarity between the appearance features, and we will compute the appearance\nfeature for each frame of the detection box. The cost for appearance association Cost\n6\ncan be directly obtained from the cosine similarity with the following formula:\nCost a_b = 1 \u2212Cosine Similarity = 1 \u2212\na \u00b7 b\n\u2225a\u2225\u2225b\u2225\n(2)\nwhere a and b denote the appearance characteristics of the detection box for two\nspecific frames, respectively. A higher cosine similarity indicates a higher appearance\nsimilarity, while a lower cosine similarity indicates that the appearance of the trajec-\ntory is different from the detection appearance. The reappeared detection of whether\nto rematch the lost trajectory needs to meet the following conditions:\n(\nCostlost_re > \u03b1\nDistlost_re > \u03b2\n(3)\nwhere Costlost_re denotes the cosine similarity between the lost trajectory\u2019s appear-\nance feature before disappearing and the reappeared detection appearance feature;\nDistlost_re represents their Euclid distance; \u03b1 and \u03b2 denote the thresholds set for\nsimilarity and distance respectively.\n3.3 Solving Same and Different Team Player Occlusion\nProblem\nIn the previous SOTA tracking method [4, 20] in SportsMOT [11] dataset, when a\ntrajectory is lost for more than a specific frame, it discards the trajectory, and when a\nnew detection frame with no trajectory matches reappears, it initializes the detection\nbox as a new trajectory, which is called the ID-increasing problem. Since we added\nBGR, the ID-increasing problem has become the ID switch problem. In addition, the\nlong-time occlusion caused by the defense, as mentioned in the previous section, will\nalso lead to the ID switch.\nFor the ID switch problem, first, we need to detect whether the player is occluded or\nnot in each frame to record the occlusion state of the player. If the player\u2019s trajectory\nis lost, it means the player has been occluded. When the player trajectory reappears,\nwe record the two players closest to the player in the Lost state in the occluded\nframe, indicating that the occluded player may have had an ID switch with these two\nplayers. In addition, we recorded the projected court position history and the ReID\nfeatures for each frame. Then, we need to categorize the occlusion into Same Team\nOcclusion (STO) and Different Team Occlusion (DTO) according to whether the two\noccluded players are on the same team or not. We can determine which situation the\nocclusion belongs to based on the ReID similarity of the two players before and after\nthe occlusion. The formula is as follows:\nOcclusion =\n\uf8f1\n\uf8f2\n\uf8f3\nSTO, if\n\f\f\fRbefore\na_N\n\u2212Rbefore\nb_N\n\f\f\f < \u03b3 or\n\f\f\fRafter\na_M \u2212Rafter\nb_M\n\f\f\f < \u03b3\nDTO, if\n\f\f\fRbefore\na_N\n\u2212Rbefore\nb_N\n\f\f\f > \u03b3 or\n\f\f\fRafter\na_M \u2212Rafter\nb_M\n\f\f\f > \u03b3\n(4)\n7\nwhere Rbefore\na_N\ndenotes the ReID features of player a for N frames before occlusion\noccurs, and Rafter\na_M denotes its ReID features for M frames after occlusion occurs. The\nsame can be applied to player b, \u03b3 denotes the similarity threshold between two players\nbefore and after occlusion, which is used to distinguish whether the occlusion is STO\nor DTO.\nSince we record the player\u2019s position, the ReID features, and the occlusion state\ninformation, we compare whether the IDs of the two players after occlusion are cor-\nrectly assigned after the M frame. For DTO, the different team uniforms will have\nlower appearance similarity, so we compare the ReID feature similarity of two trajec-\ntories before and after occlusion. If the ReID feature of one trajectory after occlusion\nis similar to the other one before occlusion, it is considered that an ID switch has\noccurred, and the formula is as follows:\n\uf8f1\n\uf8f2\n\uf8f3\n\f\f\fRbefore\na_N\n\u2212Rafter\nb_M\n\f\f\f < \u03b4\n\f\f\fRafter\na_N \u2212Rbefore\nb_M\n\f\f\f < \u03b4\n(5)\nwhere Rbefore\na_N\ndenotes the ReID feature of N frames before the occlusion of player a,\nRafter\nb_M denotes the ReID feature of M frames after the occlusion of player b, \u03b4 denotes\nthe threshold of appearance similarity of two players. Because two players typically\ndo not change much in their appearance features before and after occlusion occurs,\nSatisfying the Eq. (5) means that these two players have wrongly assigned their IDs\nafter the occlusion and need to exchange their IDs.\nFor STO, the same team uniforms will have a higher degree of appearance simi-\nlarity, so we compare the moving distance and speed of two trajectories before and\nafter occlusion. If the moving distance and velocity of one trajectory after occlusion\nare similar to the other one before occlusion, it is considered that an ID switch has\noccurred. The formulae are as follows:\n\uf8f1\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f2\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f3\n\f\f\fV before\na_N\n\u2212V after\na_M\n\f\f\f > \u03b5\n\f\f\fV before\nb_N\n\u2212V after\nb_M\n\f\f\f > \u03b5\n\f\f\f(P occ\nC\n\u2212P before\na_N\n)\n\f\f\f \u2212\n\f\f\f(P after\na_M \u2212P occ\nC )\n\f\f\f > \u03b6\n\f\f\f(P occ\nC\n\u2212P before\nb_N\n)\n\f\f\f \u2212\n\f\f\f(P after\nb_M \u2212P occ\nC )\n\f\f\f > \u03b6\n(6)\nwhere\nV before\na_N\n=\n(\n\f\f\fP occ\nC\n\u2212P before\na_N\n\f\f\f)/(|FC \u2212FN|)\nand\nV after\na_M\n=\n(\n\f\f\fP after\na_M \u2212P occ\nC\n\f\f\f)/(|FM \u2212FC|). P occ\nC\ndenotes that only one player\u2019s position can be\ndetected during occlusion, FC \u2212FN denotes the number of frames from N to C,\nFM \u2212FC denotes the number of frames from C to M. V before\na_N\n, V after\na_M\ndenotes the\nvelocity of player a and b at N frames before occlusion and M frames after occlusion,\nrespectively. V denotes the velocity and the unit is cm/frame, and P denotes the\nposition. \u03b5 and \u03b6 represent the thresholds for the velocity and position of two players,\nrespectively. Since both players don\u2019t typically make large changes in velocity and\n8\nposition at the same time when the occlusion occurs, satisfying the Eq. (6) means\nthat these two players could have wrongly assigned their IDs after the occlusion and\nneed to exchange their IDs.\n4 Experiments\n4.1 Experimental setup\nDatasets. We used the basketball fixed camera videos from the TeamTrack dataset\n[17] to validate our approach because it is considered to include frequent CMOO\nproblems among various team sport MOT datasets [11, 15\u201317]. Here, we briefly intro-\nduce the basketball fixed video dataset, which was filmed from the side view using a\nfish-eye camera. The published videos were calibrated in advance and segmented into\n30-second intervals. We split it into training and test videos with 162,353 and 170,529\nframes, respectively. In the dataset, the players and referees were labeled, which allows\nour detector to detect only the players and filter out the referees.\nMetrics. Multiple object tracking accuracy (MOTA) [29] have been often used as\nan evaluation metric for MOT tasks. However, MOTA focuses more on detection\nperformance rather than association accuracy. In basketball, we track mainly to get\nthe player\u2019s trajectory, so we need to use HOTA [30] as the evaluation metric. HOTA\nconsists of detection accuracy (DetA), localization accuracy (LocA), and association\naccuracy (AssA), the metrics combined to evaluate detection accuracy and tracking\naccuracy. The metrics combine different aspects of the MOT and HOTA to reflect the\nsystem\u2019s performance more comprehensively. In addition, false positives (FP), false\nnegatives (FN), and ID switches (IDS) can also reflect the tracking performance well.\nTherefore, we use HOTA, DetA, LocA, AssA, FP, FN, and IDS as the evaluation\nmetrics of tracking.\nDetector and ReID. In our method and baselines, we chose YOLOv8 [31] as our\nobject detector to achieve real-time and high-accuracy detection performance. We used\nthe officially provided yolov8l pre-training model to train our model with the training\ndataset. We used an SGD optimizer with a weight decay of 0.0005 and momentum of\n0.9. The initial learning rate is 0.001 and training for 200 epochs. For player ReID, we\nuse the proposed FastReID model [32] because we use ReID mainly to solve the occlu-\nsion problem, and the performance of the ReID model does not have high performance.\nAll the experiments are conducted on a single Nvidia RTX 4080 GPU.\nImplementation details. The threshold for a detection to be treated as a high-score\ndetection is 0.6. Detections with a confidence score between 0.6 and 0.1 will be treated\nas low-score detections, and the rest with a confidence score lower than 0.1 will be\nfiltered. We performed hyperparameter optimization on our method and found the best\nthreshold. RLLI threshold \u03b1 was set to 0.2 and \u03b2 set to 260; Distinguishing between\nSTO and DTO parameters \u03b3 was set to 0.2; DTO appearance similarity threshold \u03b4\nwas set to 0.2; DTO velocity similarity threshold \u03b5 was set to 3 and position threshold\n\u03b6 was set to 3.\n9\n4.2 Benchmark Results\nAmong current MOT algorithms, BoT-SORT [8] demonstrates the most representative\nperformance on large-scale pedestrian datasets such as MOT20 [2]. On the other hand,\nDeep-EIoU [20] achieves the best results on sports sense datasets like SportsMOT\n[11]. Therefore, we compare our method with recent methods such as BoT-SORT and\nDeep-EIoU on the basketball fixed video dataset, We have also included an example, as\ndepicted in Figure 4. The results are shown in Table 1. In these methods, we employed\nthe same detector, YOLOv8, for all experiments. The results show that DetA and\nLocA were quite similar, fluctuating within 1 percentage point. Therefore, we will\nomit the DetA and LocA results in the subsequent sections. The results demonstrate\nthat our method achieves the best HOTA score due to a significant improvement in\nAssA. By utilizing projected positions to associate player trajectories, our approach\ncan correctly track players even when their projected positions are far apart but their\ndetection bounding boxes overlap. Since this situation occurs frequently, it leads to a\nsubstantial reduction in IDS, resulting in a notable boost in AssA. When we employ\nBGR, we do not discard or create new trajectories. Not discarding trajectories prevents\nsome lost player trajectories from requiring their correct IDs, resulting in an increase\nin False Negatives (FN). We also show it in the ablation study below. On the other\nhand, not creating new trajectories means that some detection bounding boxes of\nreferees and spectators will not be recognized as player trajectories, thereby reducing\nFalse Positives (FP). In addition, our method yields only 10 player trajectories, which\nis significantly better than other methods. Our method achieves the best results and\noutperforms all the other previous trackers while keeping the tracking process online,\nshowing our algorithm\u2019s effectiveness in MOT for the basketball fixed video dataset.\nMethod\nHOTA (%)\nAssA (%)\nFN\nFP\nIDS\nBoT-SORT\n59.70\u00b16.43\n53.43\u00b110.05\n270.8\u00b1163.3\n492.6\u00b1369.9\n23.2\u00b113.7\nDeep-EIoU\n60.74\u00b17.72\n55.47\u00b111.62\n265.0\u00b1162.4\n486.2\u00b1368.1\n20.7\u00b110.3\nBasketball-SORT(ours)\n63.35\u00b17.21\n59.15\u00b110.61\n387.7\u00b1464.9\n118.9\u00b1191.8\n9.3\u00b15.0\nTable 1 The performance comparison among different MOT algorithms on the basketball fixed\nvideo test sets. Our algorithm outperforms all the other previous tracking algorithms and achieves\nthe best performance result in several major evaluation metrics. BoT-SORT and DeepEIoU are\nevaluated based on their official code [8, 20].\n4.3 Ablation Studies\nIn this experiment, we evaluated Basketball-SORT (as the full model) on the test set\nof the basketball fixed camera dataset using different settings, including whether to\nuse BGR, RLLI, and whether to employ STO and DTO to address occlusion issues\n(where \u201cmix\u201d indicates using both STO and DTO simultaneously). In addition, the\n\u201cProjected\u201d method, as mentioned in Section 3.1, only utilizes the projection positions\nto associate the trajectories of players. The results are shown in Table 2. We can see\nthat after adding BGR, the FP and FN decrease dramatically, which may be due\nto the insufficient amount of data resulting in some audiences being recognized as\nplayers in the game. The reasons for the increase in FN and decrease in FP caused\n10\nFig. 4 (a-c) show the results using the DeepEIoU method. During occlusion, the player ID is lost, and\nthe method fails to assign the player ID correctly. (d-f) demonstrate the results using the Basketball-\nSORT approach, which successfully matches the player ID during complete occlusion.\nby BGR are the same as in Section 4.2. STO and DTO lead to an increase in IDS\nbecause our approach to resolving occlusion issues involves identifying the occlusion\nafter it occurs and reassigning the correct ID to the player, which also results in an\nadditional IDS, thereby increasing the overall IDS count. RLLI, STO, and DTO have\nall successfully improved the HOTA, indicating that occlusion problems in the sports\nscene occur frequently. The results show that the STO+RLL method has the highest\nHOTA, probably because more of the occlusions in the dataset are STO, and some\nDTO are likely to be misclassified as STO.\nMethod\nBGR\nRLLI\nSTO\nDTO\nHOTA (%)\nAssA (%)\nFN\nFP\nIDS\nProjected\n61.96\u00b16.99\n57.32\u00b110.07\n239.6\u00b1142.7\n532.2\u00b1409.7\n20.1\u00b110.3\nBGR\n\u2713\n63.12\u00b17.55\n59.23\u00b19.89\n491.2\u00b1491.1\n110.9\u00b1162.0\n8.6\u00b15.2\nRLLI\n\u2713\n\u2713\n62.35\u00b17.02\n58.50\u00b19.59\n500.2\u00b1425.9\n156.5\u00b1194.4\n8.9\u00b15.1\nSTO\n\u2713\n\u2713\n63.45\u00b17.74\n59.57\u00b110.67\n442.9\u00b1527.8\n105.6\u00b1151.4\n8.9\u00b15.1\nSTO + RLLI\n\u2713\n\u2713\n\u2713\n63.48\u00b17.10\n59.37\u00b110.29\n386.6\u00b1465\n117.5\u00b1192.5\n9.0\u00b14.8\nDTO\n\u2713\n\u2713\n63.06\u00b17.34\n59.11\u00b19.97\n492.9\u00b1528.0\n106.9\u00b1161.0\n9.6\u00b15.4\nDTO + RLLI\n\u2713\n\u2713\n\u2713\n63.18\u00b16.75\n58.74\u00b19.80\n386.5\u00b1464.1\n117.7\u00b1193.3\n9.4\u00b15.2\nmix\n\u2713\n\u2713\n\u2713\n63.21\u00b17.84\n59.91\u00b111.01\n492.7\u00b1527.2\n105.1\u00b1161.0\n9.7\u00b15.5\nFull model\n\u2713\n\u2713\n\u2713\n\u2713\n63.35\u00b17.21\n59.15\u00b110.61\n387.7\u00b1464.9\n118.9\u00b1191.8\n9.3\u00b15.0\nTable 2 We evaluate the Basketball-SORT algorithm with different settings on the basketball\nvideo test set. Including using the Basketball Game Restriction (BGR), Reacquiring Long-Lost IDs\n(RLLI), same team occlusion (STO), and different team occlusion (DTO) for our method.\n4.4 Robustness different movement velocity\nIn basketball, the movement speed of players varies dynamically and is unpredictable.\nWhen a player is occluded, the KF still predicts its possible position in the next frame\nusing the match threshold. However, due to the instability of the player\u2019s velocity,\n11\nusing a fixed association threshold may result in the athlete being unable to rematch\nwith a newly appeared detection bounding box after the occlusion. To address this\nissue, we introduce the RLLI reacquire threshold Distlost_re as mentioned in section\n3.2, which calculates the distance between the position of the Long-Lost trajectory\nand the reappearance of the detection frame. It can effectively reduce the probability\nthat the Long-Lost player\u2019s trajectory cannot be re-matched with the new detection\nframe. In order to prove the robustness of our method, we use the RLLI model in\nTable 2 to test the effect of different match thresholds and Distlost_re on the results\nas shown in Table 3. Match threshold represents the change in position due to velocity\nvariations between adjacent frames. It is usually below 200 (cm), but in fast break\nsituations, it may reach up to 300 (cm). Therefore, we chose this range of variations\nto test our method. Distlost_re represents the distance between a Long-Lost player\u2019s\ntrajectory and the reappeared detection bounding box within B frames. We have\nset this parameter to a range of 170-250 (cm), as it corresponds to the most likely\ndistance a Long-Lost player might move within the given B frames. Since we have\ndefined the court dimensions as 2800 cm \u00d7 1400 cm, the units for the Match threshold\nand Distlost_re parameters are in centimeters (cm). The results show that different\nparameters give similar results of average HOTA 61.81%. This proves our method\u2019s\neffectiveness in the real world, where ground truth is often not available and the\ntracking parameter can not be tuned.\nMatch threshold in KF\n200\n220\n240\n260\n280\n300\nDistlost_re\n150\n61.62\n61.54\n61.69\n61.88\n61.48\n61.31\n170\n61.89\n61.71\n61.87\n61.90\n61.34\n61.48\n190\n61.88\n61.71\n61.94\n61.99\n61.33\n61.51\n210\n61.84\n61.93\n61.90\n62.34\n61.75\n61.48\n230\n61.90\n61.96\n61.93\n62.34\n61.76\n61.48\n250\n61.91\n61.96\n61.93\n62.35\n61.78\n61.48\nTable 3 We tested different match thresholds, and RLLI reacquires\nthresholds in the basketball fixed video test set. Each row parameter of\nthe table represents different Distlost_re, and each column parameter\nrepresents a different match threshold in KF. The values in the cells\nrepresent the HOTA, and various parameter configurations yield similar\nHOTA scores, indicating the robustness of the tracking method across\ndifferent settings.\n5 Conclusion\nIn this paper, we propose Basketball-SORT, an online and robust MOT approach that\nsolves the CMOO problems in basketball videos. To overcome the CMOO problem,\nwe used the trajectories of neighboring frames based on the projected positions of\nthe players. Our method designs the BGR and RLLI based on the characteristics of\nbasketball scenes, and we also solved the occlusion problem based on the player tra-\njectories and appearance features. Experimental results show that our approach can\n12\neffectively solve the CMOO problem and is much better than previous tracking algo-\nrithms. For future work, tracking basketball games filmed with moving cameras and\naddressing the more complex player occlusion issues in basketball scenes are needed\nin order to fully track the motion trajectories of athletes in more general ways.\nAcknowledgments\nThis work was financially supported by JSPS Grant Number 20H04075 and 23H03282\nand JST PRESTO Grant Number JPMJPR20CA.\nDeclarations\nConflict of Interest\nThe authors declare that they have no conflict of interest.\nData availability statements\nThe evaluation dataset in this study is available at https://github.com/AtomScott/\nTeamTrack.\nCompliance with Ethical Standards\nThe participants were fully informed about the study, and their consent was obtained\nin advance. All the experimental procedures were performed after obtaining prior\napproval from the ethical committee at Tokai University.\nReferences\n[1] Geiger, A., Lenz, P., Urtasun, R.: Are we ready for autonomous driving? the\nkitti vision benchmark suite. In: 2012 IEEE Conference on Computer Vision and\nPattern Recognition, pp. 3354\u20133361 (2012). IEEE\n[2] Dendorfer, P., Rezatofighi, H., Milan, A., Shi, J., Cremers, D., Reid, I., Roth, S.,\nSchindler, K., Leal-Taix\u00e9, L.: Mot20: A benchmark for multi object tracking in\ncrowded scenes. arXiv preprint arXiv:2003.09003 (2020)\n[3] Milan, A., Leal-Taix\u00e9, L., Reid, I., Roth, S., Schindler, K.: Mot16: A benchmark\nfor multi-object tracking. arXiv preprint arXiv:1603.00831 (2016)\n[4] Wang, J., Peng, Y., Yang, X., Wang, T., Zhang, Y.: Sportstrack: an innovative\nmethod for tracking athletes in sports scenes. arXiv preprint arXiv:2211.07173\n(2022)\n[5] Sun, P., Cao, J., Jiang, Y., Yuan, Z., Bai, S., Kitani, K., Luo, P.: Dancetrack:\nMulti-object tracking in uniform appearance and diverse motion. In: Proceedings\nof the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp.\n20993\u201321002 (2022)\n13\n[6] Bewley, A., Ge, Z., Ott, L., Ramos, F., Upcroft, B.: Simple online and realtime\ntracking. In: 2016 IEEE International Conference on Image Processing (ICIP),\npp. 3464\u20133468 (2016). IEEE\n[7] Peng, J., Wang, T., Lin, W., Wang, J., See, J., Wen, S., Ding, E.: Tpm: Multiple\nobject tracking with tracklet-plane matching. Pattern Recognition 107, 107480\n(2020)\n[8] Aharon, N., Orfaig, R., Bobrovsky, B.-Z.: Bot-sort: Robust associations multi-\npedestrian tracking. arXiv preprint arXiv:2206.14651 (2022)\n[9] Liang, C., Zhang, Z., Zhou, X., Li, B., Zhu, S., Hu, W.: Rethinking the compe-\ntition between detection and reid in multiobject tracking. IEEE Transactions on\nImage Processing 31, 3182\u20133196 (2022)\n[10] Zhang, Y., Sun, P., Jiang, Y., Yu, D., Weng, F., Yuan, Z., Luo, P., Liu, W.,\nWang, X.: Bytetrack: Multi-object tracking by associating every detection box.\nIn: European Conference on Computer Vision, pp. 1\u201321 (2022). Springer\n[11] Cui, Y., Zeng, C., Zhao, X., Yang, Y., Wu, G., Wang, L.: Sportsmot: A large multi-\nobject tracking dataset in multiple sports scenes. arXiv preprint arXiv:2304.05170\n(2023)\n[12] Zhang, Y., Wang, C., Wang, X., Zeng, W., Liu, W.: Fairmot: On the fairness of\ndetection and re-identification in multiple object tracking. International Journal\nof Computer Vision 129, 3069\u20133087 (2021)\n[13] Wojke, N., Bewley, A., Paulus, D.: Simple online and realtime tracking with a deep\nassociation metric. In: 2017 IEEE International Conference on Image Processing\n(ICIP), pp. 3645\u20133649 (2017). IEEE\n[14] Cao, J., Pang, J., Weng, X., Khirodkar, R., Kitani, K.: Observation-centric\nsort: Rethinking sort for robust multi-object tracking. In: Proceedings of the\nIEEE/CVF Conference on Computer Vision and Pattern Recognition, pp.\n9686\u20139696 (2023)\n[15] Cioppa, A., Giancola, S., Deliege, A., Kang, L., Zhou, X., Cheng, Z., Ghanem,\nB., Van Droogenbroeck, M.: Soccernet-tracking: Multiple object tracking dataset\nand benchmark in soccer videos. In: Proceedings of the IEEE/CVF Conference\non Computer Vision and Pattern Recognition, pp. 3491\u20133502 (2022)\n[16] Scott, A., Uchida, I., Onishi, M., Kameda, Y., Fukui, K., Fujii, K.: Soccertrack:\nA dataset and tracking algorithm for soccer with fish-eye and drone videos.\nIn: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern\nRecognition, pp. 3569\u20133579 (2022)\n[17] Scott, A., Uchida, I., Ding, N., Umemoto, R., Bunker, R., Kobayashi, R., Koyama,\n14\nT., Onishi, M., Kameda, Y., Fujii, K.: Teamtrack: A dataset for multi-sport multi-\nobject tracking in full-pitch videos. In: Proceedings of the IEEE/CVF Conference\non Computer Vision and Pattern Recognition (2024)\n[18] Kalman, R.E., et al.: Contributions to the theory of optimal control. Boletin\nSociedad Matematica Mexicana 5(2), 102\u2013119 (1960)\n[19] Yang, F., Odashima, S., Masui, S., Jiang, S.: Hard to track objects with irreg-\nular motions and similar appearances? make it easier by buffering the matching\nspace. In: Proceedings of the IEEE/CVF Winter Conference on Applications of\nComputer Vision, pp. 4799\u20134808 (2023)\n[20] Huang, H.-W., Yang, C.-Y., Sun, J., Kim, P.-K., Kim, K.-J., Lee, K., Huang, C.-\nI., Hwang, J.-N.: Iterative scale-up expansioniou and deep features association\nfor multi-object tracking in sports. In: Proceedings of the IEEE/CVF Winter\nConference on Applications of Computer Vision, pp. 163\u2013172 (2024)\n[21] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N.,\nKaiser, \u0141., Polosukhin, I.: Attention is all you need. Advances in neural informa-\ntion processing systems 30 (2017)\n[22] Cao, J., Wu, H., Kitani, K.: Track targets by dense spatio-temporal position\nencoding. arXiv preprint arXiv:2210.09455 (2022)\n[23] Zeng, F., Dong, B., Zhang, Y., Wang, T., Zhang, X., Wei, Y.: Motr: End-to-end\nmultiple-object tracking with transformer. In: European Conference on Computer\nVision, pp. 659\u2013675 (2022). Springer\n[24] Sun, P., Cao, J., Jiang, Y., Zhang, R., Xie, E., Yuan, Z., Wang, C., Luo,\nP.: Transtrack: Multiple object tracking with transformer. arXiv preprint\narXiv:2012.15460 (2020)\n[25] Vats, K., Walters, P., Fani, M., Clausi, D.A., Zelek, J.S.: Player tracking and\nidentification in ice hockey. Expert Systems with Applications 213, 119250 (2023)\n[26] Maglo, A., Orcesi, A., Pham, Q.-C.: Efficient tracking of team sport players with\nfew game-specific annotations. In: Proceedings of the IEEE/CVF Conference on\nComputer Vision and Pattern Recognition, pp. 3461\u20133471 (2022)\n[27] Sang\u00fcesa, A.A., Ballester, C., Haro, G.: Single-camera basketball tracker through\npose and semantic feature fusion. CoRR, abs/1906.02042 (2019)\n[28] Huang, H.-W., Yang, C.-Y., Ramkumar, S., Huang, C.-I., Hwang, J.-N., Kim, P.-\nK., Lee, K., Kim, K.: Observation centric and central distance recovery for athlete\ntracking. In: Proceedings of the IEEE/CVF Winter Conference on Applications\nof Computer Vision, pp. 454\u2013460 (2023)\n15\n[29] Bernardin, K., Stiefelhagen, R.: Evaluating multiple object tracking performance:\nthe clear mot metrics. EURASIP Journal on Image and Video Processing 2008,\n1\u201310 (2008)\n[30] Luiten, J., Osep, A., Dendorfer, P., Torr, P., Geiger, A., Leal-Taix\u00e9, L., Leibe, B.:\nHota: A higher order metric for evaluating multi-object tracking. International\njournal of computer vision 129, 548\u2013578 (2021)\n[31] Jocher, G., Chaurasia, A., Qiu, J.: YOLO by Ultralytics (2023). https://github.\ncom/ultralytics/ultralytics\n[32] He, L., Liao, X., Liu, W., Liu, X., Cheng, P., Mei, T.: Fastreid: A pytorch\ntoolbox for general instance re-identification. In: Proceedings of the 31st ACM\nInternational Conference on Multimedia, pp. 9664\u20139667 (2023)\n16\n",
    "tags": []
  }
]